{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import base64\n",
    "import string\n",
    "import re\n",
    "from collections import Counter\n",
    "import sklearn\n",
    "import xlrd\n",
    "import nltk as nltk\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib.colors import ListedColormap\n",
    "from os import path\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Data...\n",
      "Data Loaded\n",
      "Tokenizing...\n",
      "Tokenization Completed\n",
      "Training...\n",
      "Epoch 1/13\n",
      "15539/15539 [==============================] - 59s 4ms/step - loss: 0.6489 - acc: 0.6110\n",
      "Epoch 2/13\n",
      "15539/15539 [==============================] - 59s 4ms/step - loss: 0.5721 - acc: 0.6991\n",
      "Epoch 3/13\n",
      "15539/15539 [==============================] - 83s 5ms/step - loss: 0.5247 - acc: 0.7387\n",
      "Epoch 4/13\n",
      "15539/15539 [==============================] - 73s 5ms/step - loss: 0.4940 - acc: 0.7617\n",
      "Epoch 5/13\n",
      "15539/15539 [==============================] - 73s 5ms/step - loss: 0.4646 - acc: 0.7815\n",
      "Epoch 6/13\n",
      "15539/15539 [==============================] - 75s 5ms/step - loss: 0.4489 - acc: 0.7910\n",
      "Epoch 7/13\n",
      "15539/15539 [==============================] - 84s 5ms/step - loss: 0.4298 - acc: 0.8071\n",
      "Epoch 8/13\n",
      "15539/15539 [==============================] - 72s 5ms/step - loss: 0.4125 - acc: 0.8172\n",
      "Epoch 9/13\n",
      "15539/15539 [==============================] - 78s 5ms/step - loss: 0.4004 - acc: 0.8251\n",
      "Epoch 10/13\n",
      "15539/15539 [==============================] - 84s 5ms/step - loss: 0.3875 - acc: 0.8326\n",
      "Epoch 11/13\n",
      "15539/15539 [==============================] - 74s 5ms/step - loss: 0.3849 - acc: 0.8319\n",
      "Epoch 12/13\n",
      "15539/15539 [==============================] - 60s 4ms/step - loss: 0.3719 - acc: 0.8365\n",
      "Epoch 13/13\n",
      "15539/15539 [==============================] - 83s 5ms/step - loss: 0.3719 - acc: 0.8401\n",
      "Training Completed\n",
      "Testing Against Control... (% of the data)  0.0\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'acc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-f05947ed039a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[0mtokenized_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m \u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenized_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0memotion_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[0;31m#test(model, X_test, tokenized_data, sentence_list, emotion_list)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-f05947ed039a>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(tokened_sentences, emotion_list)\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0;31m#score,acc = model.evaluate(X_test, Y_test, verbose = 2, batch_size = batch_size)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;31m#print(\"Score   :\", score)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Accuracy:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m     \u001b[0mfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'acc' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import base64\n",
    "import string\n",
    "import re\n",
    "from collections import Counter\n",
    "import sklearn\n",
    "import xlrd\n",
    "import nltk as nltk\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib.colors import ListedColormap\n",
    "from os import path\n",
    "from PIL import Image\n",
    "from __future__ import unicode_literals, print_function\n",
    "import plac\n",
    "import random\n",
    "from pathlib import Path\n",
    "import thinc.extra.datasets\n",
    "import pandas as pd\n",
    "import spacy\n",
    "from spacy.util import minibatch, compounding\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "from numpy import array, unique, array_equal\n",
    "import keras\n",
    "max_fatures = 3500\n",
    "from keras import regularizers\n",
    "\n",
    "\n",
    "def load_data():\n",
    "    print(\"Loading Data...\")\n",
    "    TwitterEmotion = pd.read_csv('text_emotion.csv')\n",
    "    print(\"Data Loaded\")\n",
    "    return (TwitterEmotion['content'], array(TwitterEmotion['sentiment']))\n",
    "\n",
    "\n",
    "#Below the data is sorted into nine emotion groups. Eight of the groups are the outter layer of the wheel, or the combinations of \n",
    "#two emotion groups. The ninth group is \"Ambiguous\" and \"Neutral\" put together.\n",
    "def sort_to_2_emotions(sentence_list, emotion_list):\n",
    "    sorted_list = []\n",
    "    sorted_emo = []\n",
    "    for (data, emo) in zip(sentence_list, emotion_list):\n",
    "        if (emo == 'enthusiam' or emo == 'love' or emo == 'happiness'):\n",
    "            sorted_list.append(data)\n",
    "            sorted_emo.append(\"positive\")\n",
    "        if (emo == 'sadness' or emo == 'hate'):\n",
    "            sorted_list.append(data)\n",
    "            sorted_emo.append(\"negative\")\n",
    "    return (sorted_list, sorted_emo)\n",
    "\n",
    "\n",
    "\n",
    "def tokenize(sentences):\n",
    "    print(\"Tokenizing...\")\n",
    "    tokenizer = Tokenizer(num_words=max_fatures, split=' ',lower=True)\n",
    "    tokenizer.fit_on_texts(sentences)\n",
    "    X = tokenizer.texts_to_sequences(sentences)\n",
    "    X = pad_sequences(X)\n",
    "    print(\"Tokenization Completed\")\n",
    "    return X\n",
    "\n",
    "\n",
    "\n",
    "def train(tokened_sentences, emotion_list):\n",
    "    print(\"Training...\")\n",
    "    embed_dim = 128\n",
    "    lstm_out = 196\n",
    "    test_percent=.0\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(max_fatures, embed_dim,input_length = tokened_sentences.shape[1]))\n",
    "    model.add(SpatialDropout1D(0.7))\n",
    "    model.add(keras.layers.Dropout(.6))\n",
    "\n",
    "    model.add(LSTM(lstm_out, dropout=0.65, recurrent_dropout=0.65))\n",
    "    \n",
    "    # len(set(emotion_list)) is a hacky way of geting the number of unique elements\n",
    "    # in a regualar python list (non-numpy)\n",
    "    model.add(Dense(unique(emotion_list).size,activation='softmax'))\n",
    "    model.compile(loss = 'binary_crossentropy', optimizer=keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, amsgrad=True ),metrics = ['accuracy'])\n",
    "    #print(model.summary())\n",
    "\n",
    "    Y = pd.get_dummies(emotion_list).values\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(tokened_sentences,Y, test_size = test_percent, random_state = 152321326)\n",
    "    #print(X_train.shape,Y_train.shape)\n",
    "    #print(X_test.shape,Y_test.shape)\n",
    "    \n",
    "    batch_size = 32\n",
    "    hist = model.fit(X_train, Y_train, epochs = 13, batch_size=batch_size, verbose = 1,validation_split=.0)\n",
    "    print(\"Training Completed\")\n",
    "    print(\"Testing Against Control... (% of the data) \", test_percent)\n",
    "    #score,acc = model.evaluate(X_test, Y_test, verbose = 2, batch_size = batch_size)\n",
    "    #print(\"Score   :\", score)\n",
    "    #print(\"Accuracy:\", acc)\n",
    "    fig = plt.figure(figsize=(7,7))\n",
    "    plt.plot(hist.history['acc'])\n",
    "    if(val_split != 0.0):\n",
    "        plt.plot(hist.history['val_acc'])\n",
    "    plt.title('Model Accuracy')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.legend(['Training Set', 'Validation Set'], loc='upper left')\n",
    "    plt.show()\n",
    "    \n",
    "    plt.plot(hist.history['loss'])\n",
    "    if(val_split != 0.0):\n",
    "        plt.plot(hist.history['val_loss'])\n",
    "    plt.title('Model Loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['Training Set', 'Validation Set'], loc='upper left')\n",
    "    plt.show()\n",
    "    return (model, X_test)\n",
    "\n",
    "### When Splitting data (train_test_split), we don't retain where in the \n",
    "### origional set the data is located, thus it takes\n",
    "### a little trickery to see the results while while only testing against untrained data\n",
    "### top_predictions variable changes how many predictions given\n",
    "def test(model, X_test, tokenized_data, sentence_list, emotion_list, top_predictions=1):\n",
    "    predictions = model.predict(tokenized_data, batch_size=32)\n",
    "    error = 0\n",
    "    for i in range(len(predictions)):\n",
    "     \n",
    "        #  \"If the current tokenized data array is in X_test (untrained tokenized arrays)\n",
    "        \n",
    "        if(any(array_equal(tokenized_data[i], x) for x in X_test)):\n",
    "            print(\"\\n\\n\")\n",
    "\n",
    "            \n",
    "            pos = list(predictions[i]).index(max(predictions[i]))\n",
    "            if (unique(emotion_list)[pos] != emotion_list[i]):\n",
    "                error += 1\n",
    "            temp = predictions[i]\n",
    "            \n",
    "            print(sentence_list[i])\n",
    "\n",
    "            for j in range(top_predictions):\n",
    "                pos = list(temp).index(max(temp))\n",
    "                print(\"\\n # %s Predicted emotion : \",j+1, unique(emotion_list)[pos])\n",
    "                temp[pos] = 0\n",
    "            print(\"Actual emotion   : \", emotion_list[i])\n",
    "\n",
    "    print(\"%  Accuracy when against untrained set: \", 1- (float(error) / len(X_test)))\n",
    "\n",
    "def count_errors(model, tokenized_data, sentence_list, emotion_list, X_test):\n",
    "    dims =  len(unique(emotion_list))\n",
    "    mistake_list = np.zeros((dims,dims), dtype=np.int)\n",
    "    predictions = model.predict(tokenized_data, batch_size=32)\n",
    "    print(\"Total predictions:\", len(predictions))\n",
    "    for i in range(len(predictions)):\n",
    "        if(any(array_equal(tokenized_data[i], x) for x in X_test)):\n",
    "            pos = list(predictions[i]).index(max(predictions[i]))\n",
    "            mistake_list[list(unique(emotion_list)).index(emotion_list[i])][pos] += 1\n",
    "   # for i in range(len(mistake_list)):\n",
    "   #     for j in range(len(mistake_list)):\n",
    "   #         mistake_list[i][j] = mistake_list[i][j] * 100 / list(emotion_list).count(unique(emotion_list)[i]) \n",
    "    print(mistake_list)\n",
    "    return mistake_list\n",
    "\n",
    "\n",
    "def graph_errors(mistake_list, emotion_list):\n",
    "    dim = len(mistake_list[0])\n",
    "    \n",
    "    false =  np.zeros((dim,4), dtype=np.int)\n",
    "    \n",
    "    #total number of testing data for each category\n",
    "    for i in range(dim):\n",
    "        for j in range(dim):\n",
    "            false[i][0] += mistake_list[i][j]\n",
    "\n",
    "    \n",
    "    #true positives\n",
    "    for i in range(dim):\n",
    "              false[i][1] = mistake_list[i][i]\n",
    "    #false positives\n",
    "    for i in range(dim):\n",
    "        sum = 0\n",
    "        for j in range(dim):\n",
    "            if (i != j):\n",
    "                sum += mistake_list[i][j]\n",
    "        false[i][2] = sum\n",
    "   #     \n",
    "  #          #false Negatives\n",
    "    for i in range(dim):\n",
    "        sum = 0\n",
    "        for j in range(dim):\n",
    "            if (i != j):\n",
    "                sum += mistake_list[j][i]\n",
    "        false[i][3] = sum\n",
    "    df = pd.DataFrame(false)\n",
    "    #, \"False Positives\", \"False Negatives\"\n",
    "    \n",
    "    df.columns = [\"Total Predictions\", \"Correct\",\"False Positives\",\"False Negatives\"]\n",
    "    df.insert(0, \"Emotion\", np.unique(emotion_list))\n",
    "    (_, counts) = np.unique(emotion_list,return_counts=True)\n",
    "   # for i in range(counts.size):\n",
    "   #     counts[i] = counts[i] / 60\n",
    "   # df.insert(1,\"Amount of Data / 10\",counts)\n",
    "    print(df.to_latex())\n",
    "    df.plot.bar(x='Emotion',figsize=(12,8),colormap=cm.get_cmap('summer'))\n",
    "    #plot = sns.barplot(x=\"Emotion\",y=Correct, data=df)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#################################\n",
    "#############MAIN################\n",
    "#################################\n",
    "#   jupyter notebook is weird   #\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "(sentence_list, emotion_list) = load_data()\n",
    "\n",
    "\n",
    "### Comment the Below line for all 18 emotions. This sorts into \"positive\" and \"negative\"\n",
    "sentence_list, emotion_list = sort_to_2_emotions(sentence_list, emotion_list)\n",
    "\n",
    "tokenized_data = tokenize(sentence_list)\n",
    "\n",
    "(model, X_test) = train(tokenized_data, emotion_list)\n",
    "\n",
    "#test(model, X_test, tokenized_data, sentence_list, emotion_list)\n",
    "\n",
    "mistake_list = count_errors(model, tokenized_data, sentence_list, emotion_list,X_test)\n",
    "\n",
    "graph_errors(mistake_list, emotion_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Emotion  Correct  Emotions in Category\n",
      "0  negative     4858                  6488\n",
      "1  positive     8161                  9051\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# fig = plt.figure(figsize=(20,4))\n",
    "#sns.barplot(x = ProjectData['emotion'].unique(), y=ProjectData['emotion'].value_counts())\n",
    "#plt.show()\n",
    "from matplotlib import cm\n",
    "graph_errors(mistake_list, emotion_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
