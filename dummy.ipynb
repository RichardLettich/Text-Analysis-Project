{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import base64\n",
    "import string\n",
    "import re\n",
    "from collections import Counter\n",
    "import sklearn\n",
    "import xlrd\n",
    "import nltk as nltk\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib.colors import ListedColormap\n",
    "from os import path\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n",
      "Loading Data...\n",
      "Data Loaded\n",
      "negative\n",
      "Tokenizing...\n",
      "Tokenization Completed\n",
      "Training...\n",
      "Epoch 1/13\n",
      "15539/15539 [==============================] - 50s 3ms/step - loss: 0.6503 - acc: 0.6070\n",
      "Epoch 2/13\n",
      "15539/15539 [==============================] - 53s 3ms/step - loss: 0.5702 - acc: 0.6979\n",
      "Epoch 3/13\n",
      "15539/15539 [==============================] - 51s 3ms/step - loss: 0.5264 - acc: 0.7376\n",
      "Epoch 4/13\n",
      "15539/15539 [==============================] - 45s 3ms/step - loss: 0.4916 - acc: 0.7658\n",
      "Epoch 5/13\n",
      "15539/15539 [==============================] - 49s 3ms/step - loss: 0.4596 - acc: 0.7862\n",
      "Epoch 6/13\n",
      "15539/15539 [==============================] - 51s 3ms/step - loss: 0.4401 - acc: 0.8010: 0s - loss: 0.4390 - acc: \n",
      "Epoch 7/13\n",
      "15539/15539 [==============================] - 45s 3ms/step - loss: 0.4252 - acc: 0.8064\n",
      "Epoch 8/13\n",
      "15539/15539 [==============================] - 46s 3ms/step - loss: 0.4122 - acc: 0.8154\n",
      "Epoch 9/13\n",
      "15539/15539 [==============================] - 55s 4ms/step - loss: 0.3984 - acc: 0.8228\n",
      "Epoch 10/13\n",
      "15539/15539 [==============================] - 47s 3ms/step - loss: 0.3895 - acc: 0.8264\n",
      "Epoch 11/13\n",
      "15539/15539 [==============================] - 45s 3ms/step - loss: 0.3836 - acc: 0.8327\n",
      "Epoch 12/13\n",
      "15539/15539 [==============================] - 51s 3ms/step - loss: 0.3764 - acc: 0.8371\n",
      "Epoch 13/13\n",
      "15539/15539 [==============================] - 45s 3ms/step - loss: 0.3707 - acc: 0.8403\n",
      "Training Completed\n",
      "Testing Against Control... (% of the data)  0\n",
      "Loading  tweets_unlabeled/out2.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/py36/lib/python3.6/site-packages/ipykernel_launcher.py:293: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================================\n",
      "Please add the following lines to your LaTeX preamble:\n",
      "\n",
      "\\usepackage[utf8]{inputenc}\n",
      "\\usepackage{fontspec} % This line only for XeLaTeX and LuaLaTeX\n",
      "\\usepackage{pgfplots}\n",
      "=========================================================\n",
      "Horizontal alignment will be ignored as no 'x tick label text width' has been passed in the 'extra' parameter\n",
      "Horizontal alignment will be ignored as no 'y tick label text width' has been passed in the 'extra' parameter\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x900 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading  tweets_unlabeled/panera.csv\n",
      "=========================================================\n",
      "Please add the following lines to your LaTeX preamble:\n",
      "\n",
      "\\usepackage[utf8]{inputenc}\n",
      "\\usepackage{fontspec} % This line only for XeLaTeX and LuaLaTeX\n",
      "\\usepackage{pgfplots}\n",
      "=========================================================\n",
      "Horizontal alignment will be ignored as no 'x tick label text width' has been passed in the 'extra' parameter\n",
      "Horizontal alignment will be ignored as no 'y tick label text width' has been passed in the 'extra' parameter\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x900 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading  tweets_unlabeled/chip.csv\n",
      "=========================================================\n",
      "Please add the following lines to your LaTeX preamble:\n",
      "\n",
      "\\usepackage[utf8]{inputenc}\n",
      "\\usepackage{fontspec} % This line only for XeLaTeX and LuaLaTeX\n",
      "\\usepackage{pgfplots}\n",
      "=========================================================\n",
      "Horizontal alignment will be ignored as no 'x tick label text width' has been passed in the 'extra' parameter\n",
      "Horizontal alignment will be ignored as no 'y tick label text width' has been passed in the 'extra' parameter\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x900 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading  tweets_unlabeled/pals.csv\n",
      "=========================================================\n",
      "Please add the following lines to your LaTeX preamble:\n",
      "\n",
      "\\usepackage[utf8]{inputenc}\n",
      "\\usepackage{fontspec} % This line only for XeLaTeX and LuaLaTeX\n",
      "\\usepackage{pgfplots}\n",
      "=========================================================\n",
      "Horizontal alignment will be ignored as no 'x tick label text width' has been passed in the 'extra' parameter\n",
      "Horizontal alignment will be ignored as no 'y tick label text width' has been passed in the 'extra' parameter\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x900 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading  tweets_unlabeled/tacobell.csv\n",
      "=========================================================\n",
      "Please add the following lines to your LaTeX preamble:\n",
      "\n",
      "\\usepackage[utf8]{inputenc}\n",
      "\\usepackage{fontspec} % This line only for XeLaTeX and LuaLaTeX\n",
      "\\usepackage{pgfplots}\n",
      "=========================================================\n",
      "Horizontal alignment will be ignored as no 'x tick label text width' has been passed in the 'extra' parameter\n",
      "Horizontal alignment will be ignored as no 'y tick label text width' has been passed in the 'extra' parameter\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x900 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading  tweets_unlabeled/comxfc.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import base64\n",
    "import string\n",
    "import re\n",
    "from collections import Counter\n",
    "import sklearn\n",
    "import xlrd\n",
    "import nltk as nltk\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib.colors import ListedColormap\n",
    "from os import path\n",
    "from PIL import Image\n",
    "from __future__ import unicode_literals, print_function\n",
    "import plac\n",
    "import random\n",
    "from pathlib import Path\n",
    "import thinc.extra.datasets\n",
    "import pandas as pd\n",
    "import spacy\n",
    "from spacy.util import minibatch, compounding\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import matplotlib.style as style \n",
    "from numpy import array, unique, array_equal\n",
    "import keras\n",
    "max_fatures = 3500\n",
    "from keras import regularizers\n",
    "from scipy.stats import expon\n",
    "from matplotlib2tikz import save as tikz_save\n",
    "\n",
    "def load_data_self():\n",
    "    print(\"Loading Data...\")\n",
    "    PrimaryEmotion = pd.read_csv('emotion.xls.csv')\n",
    "    print(\"Data Loaded\")\n",
    "    return (PrimaryEmotion['sentence'], array(PrimaryEmotion['emotion']))\n",
    "\n",
    "\n",
    "\n",
    "def sort_to_2_emotions_self(sentence_list, emotion_list):\n",
    "    sorted_list = []\n",
    "    sorted_emo = []\n",
    "    for (data, emo) in zip(sentence_list, emotion_list):\n",
    "        if (emo == 'Joy' or emo == 'Love' or emo == 'Optimism' or emo == 'Awe' or emo == 'Trust'):\n",
    "            sorted_list.append(data)\n",
    "            sorted_emo.append(\"positive\")\n",
    "        if (emo == 'Anger' or emo == 'Disgust' or emo == 'Sadness' or emo == 'Aggression' or emo == 'Contempt' or emo == 'Disapproval' or emo == 'Remorse'):\n",
    "            sorted_list.append(data)\n",
    "            sorted_emo.append(\"negative\")\n",
    "    return (sorted_list, sorted_emo)\n",
    "\n",
    "def load_data():\n",
    "    print(\"Loading Data...\")\n",
    "    TwitterEmotion = pd.read_csv('text_emotion.csv')\n",
    "    print(\"Data Loaded\")\n",
    "    return (TwitterEmotion['content'], TwitterEmotion['sentiment'])\n",
    "\n",
    "def load_unlabeled_tweets(filepath):\n",
    "    print(\"Loading \",filepath)\n",
    "    return array(pd.read_csv(filepath,dtype=str,skip_blank_lines=True)['text'])\n",
    "\n",
    "#Below the data is sorted into nine emotion groups. Eight of the groups are the outter layer of the wheel, or the combinations of \n",
    "#two emotion groups. The ninth group is \"Ambiguous\" and \"Neutral\" put together.\n",
    "def sort_to_2_emotions(sentence_list, emotion_list):\n",
    "    sorted_list = []\n",
    "    sorted_emo = []\n",
    "    for (data, emo) in zip(sentence_list, emotion_list):\n",
    "        if (emo == 'enthusiam' or emo == 'love' or emo == 'happiness'):\n",
    "            sorted_list.append(data)\n",
    "            sorted_emo.append(\"positive\")\n",
    "        if (emo == 'sadness' or emo == 'hate'):\n",
    "            sorted_list.append(data)\n",
    "            sorted_emo.append(\"negative\")\n",
    "    return (sorted_list, sorted_emo)\n",
    "\n",
    "\n",
    "\n",
    "def tokenize(sentences,return_tokenizer=False):\n",
    "    print(\"Tokenizing...\")\n",
    "    tokenizer = Tokenizer(num_words=max_fatures, split=' ',lower=True)\n",
    "    tokenizer.fit_on_texts(sentences)\n",
    "    X = tokenizer.texts_to_sequences(sentences)\n",
    "    X = pad_sequences(X)\n",
    "    print(\"Tokenization Completed\")\n",
    "    if (return_tokenizer==True):\n",
    "        return(X,tokenizer)\n",
    "    return X\n",
    "\n",
    "\n",
    "\n",
    "def train(tokened_sentences, emotion_list,return_acc=False):\n",
    "    print(\"Training...\")\n",
    "    embed_dim = 128\n",
    "    lstm_out = 196\n",
    "    test_percent=0\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(max_fatures, embed_dim))#input_length = tokened_sentences.shape[1]))\n",
    "    model.add(SpatialDropout1D(0.7))\n",
    "    model.add(keras.layers.Dropout(.6))\n",
    "\n",
    "    model.add(LSTM(lstm_out, dropout=0.65, recurrent_dropout=0.65))\n",
    "    \n",
    "    # len(set(emotion_list)) is a hacky way of geting the number of unique elements\n",
    "    # in a regualar python list (non-numpy)\n",
    "    model.add(Dense(unique(emotion_list).size,activation='softmax'))\n",
    "    model.compile(loss = 'binary_crossentropy', optimizer=keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, amsgrad=True ),metrics = ['accuracy'])\n",
    "    #print(model.summary())\n",
    "\n",
    "    Y = pd.get_dummies(emotion_list).values\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(tokened_sentences,Y, test_size = test_percent, random_state = 152321326)\n",
    "    #print(X_train.shape,Y_train.shape)\n",
    "    #print(X_test.shape,Y_test.shape)\n",
    "    \n",
    "    batch_size = 32\n",
    "    hist = model.fit(X_train, Y_train, epochs = 13, batch_size=batch_size, verbose = 1,validation_split=.0)\n",
    "    print(\"Training Completed\")\n",
    "    print(\"Testing Against Control... (% of the data) \", test_percent)\n",
    "   # score,acc = model.evaluate(X_test, Y_test, verbose = 2, batch_size = batch_size)\n",
    "    #print(\"Score   :\", score)\n",
    "    #print(\"Accuracy:\", acc)\n",
    "  #  fig = plt.figure(figsize=(7,7))\n",
    "  #  plt.plot(hist.history['acc'])\n",
    "    #if(val_split != 0.0):\n",
    "  #  plt.plot(hist.history['val_acc'])\n",
    "  #  plt.title('Model Accuracy')\n",
    "  #  plt.ylabel('Accuracy')\n",
    "   # plt.xlabel('Epochs')\n",
    "    #plt.legend(['Training Set', 'Validation Set'], loc='upper left')\n",
    "  #  plt.show()\n",
    "  #  plot.savefig('Twitter_data_loss_plot.eps', format='eps', dpi=1200)\n",
    "    \n",
    "   # plt.plot(hist.history['loss'])\n",
    "   # if(val_split != 0.0):\n",
    "   # plt.plot(hist.history['val_loss'])\n",
    "   # plt.title('Model Loss')\n",
    "   # plt.ylabel('loss')\n",
    "   # plt.xlabel('epoch')\n",
    "   # plt.legend(['Training Set', 'Validation Set'], loc='upper left')\n",
    "   # plt.show()\n",
    "   # plt.savefig('Twitter_data_loss_plot.eps', format='eps', dpi=1200)\n",
    "    if(return_acc == True):\n",
    "        return (model, X_test,acc)\n",
    "    return (model, X_test)\n",
    "\n",
    "### When Splitting data (train_test_split), we don't retain where in the \n",
    "### origional set the data is located, thus it takes\n",
    "### a little trickery to see the results while while only testing against untrained data\n",
    "### top_predictions variable changes how many predictions given\n",
    "def test(model, X_test, tokenized_data, sentence_list, emotion_list, top_predictions=1):\n",
    "    predictions = model.predict(tokenized_data, batch_size=32)\n",
    "    error = 0\n",
    "    for i in range(len(predictions)):\n",
    "     \n",
    "        #  \"If the current tokenized data array is in X_test (untrained tokenized arrays)\n",
    "        \n",
    "        if(any(array_equal(tokenized_data[i], x) for x in X_test)):\n",
    "            print(\"\\n\\n\")\n",
    "\n",
    "            \n",
    "            pos = list(predictions[i]).index(max(predictions[i]))\n",
    "            if (unique(emotion_list)[pos] != emotion_list[i]):\n",
    "                error += 1\n",
    "            temp = predictions[i]\n",
    "            \n",
    "            print(sentence_list[i])\n",
    "\n",
    "            for j in range(top_predictions):\n",
    "                pos = list(temp).index(max(temp))\n",
    "                print(\"\\n # %s Predicted emotion : \",j+1, unique(emotion_list)[pos])\n",
    "                temp[pos] = 0\n",
    "            print(\"Actual emotion   : \", emotion_list[i])\n",
    "\n",
    "    print(\"%  Accuracy when against untrained set: \", 1- (float(error) / len(X_test)))\n",
    "\n",
    "def count_errors(model, tokenized_data, sentence_list, emotion_list, X_test):\n",
    "    dims =  len(unique(emotion_list))\n",
    "    mistake_list = np.zeros((dims,dims), dtype=np.int)\n",
    "    predictions = model.predict(tokenized_data, batch_size=32)\n",
    "    print(\"Total predictions:\", len(predictions))\n",
    "    for i in range(len(predictions)):\n",
    "        if(any(array_equal(tokenized_data[i], x) for x in X_test)):\n",
    "            pos = list(predictions[i]).index(max(predictions[i]))\n",
    "            mistake_list[list(unique(emotion_list)).index(emotion_list[i])][pos] += 1\n",
    "   # for i in range(len(mistake_list)):\n",
    "   #     for j in range(len(mistake_list)):\n",
    "   #         mistake_list[i][j] = mistake_list[i][j] * 100 / list(emotion_list).count(unique(emotion_list)[i]) \n",
    "    print(mistake_list)\n",
    "    return mistake_list\n",
    "\n",
    "\n",
    "def graph_errors(mistake_list, emotion_list):\n",
    "    dim = len(mistake_list[0])\n",
    "    \n",
    "    false =  np.zeros((dim,4), dtype=np.int)\n",
    "    \n",
    "    #total number of testing data for each category\n",
    "    for i in range(dim):\n",
    "        for j in range(dim):\n",
    "            false[i][0] += mistake_list[i][j]\n",
    "\n",
    "    \n",
    "    #true positives\n",
    "    for i in range(dim):\n",
    "              false[i][1] = mistake_list[i][i]\n",
    "    #false positives\n",
    "    for i in range(dim):\n",
    "        sum = 0\n",
    "        for j in range(dim):\n",
    "            if (i != j):\n",
    "                sum += mistake_list[i][j]\n",
    "        false[i][2] = sum\n",
    "   #     \n",
    "  #          #false Negatives\n",
    "    for i in range(dim):\n",
    "        sum = 0\n",
    "        for j in range(dim):\n",
    "            if (i != j):\n",
    "                sum += mistake_list[j][i]\n",
    "        false[i][3] = sum\n",
    "    df = pd.DataFrame(false)\n",
    "    #, \"False Positives\", \"False Negatives\"\n",
    "    \n",
    "    df.columns = [\"Total Predictions\", \"Correct\",\"False Positives\",\"False Negatives\"]\n",
    "    df.insert(0, \"Emotion\", np.unique(emotion_list))\n",
    "    (_, counts) = np.unique(emotion_list,return_counts=True)\n",
    "   # for i in range(counts.size):\n",
    "   #     counts[i] = counts[i] / 60\n",
    "   # df.insert(1,\"Amount of Data / 10\",counts)\n",
    "    print(df.to_latex())\n",
    "    df.plot.bar(x='Emotion',figsize=(3,2),colormap=cm.get_cmap('summer'))\n",
    "    #plot = sns.barplot(x=\"Emotion\",y=Correct, data=df)\n",
    "\n",
    "def make_comparison():\n",
    "    print(\"hello\")\n",
    "    \n",
    "    (sentence_list, emotion_list) = load_data()\n",
    "\n",
    "    ### Comment the Below line for all 18 emotions. This sorts into \"positive\" and \"negative\"\n",
    "    sentence_list, emotion_list = sort_to_2_emotions(sentence_list, emotion_list)\n",
    "    print(emotion_list[0])\n",
    "    (tokenized_data,token) = tokenize(sentence_list,return_tokenizer=True)\n",
    "\n",
    "    (model, X_test) = train(tokenized_data, emotion_list)\n",
    "\n",
    "    #,'McDonald\\'s\n",
    "    #index = ['Chick-fil-A',\"Panera\",'McDonald\\'s','Chipotle','Pal\\'s']\n",
    "    index = ['Chick-fil-A',\"Panera\",'Chipotle','Pal\\'s','Taco Bell', 'Comcast']\n",
    "    columns= ['Percent Positive']\n",
    "    \n",
    "    df = pd.DataFrame(index=index, columns=columns)\n",
    "    \n",
    "    filepaths = ['tweets_unlabeled/out2.csv',\n",
    "                 'tweets_unlabeled/panera.csv',\n",
    "                 'tweets_unlabeled/chip.csv',\n",
    "                 'tweets_unlabeled/pals.csv',\n",
    "                 'tweets_unlabeled/tacobell.csv',\n",
    "                 'tweets_unlabeled/comxfc.csv',\n",
    "                ]\n",
    "    colors = [\n",
    "        'r',\n",
    "        'olivedrab',\n",
    "        'firebrick',\n",
    "        'turquoise',\n",
    "        'darkviolet',\n",
    "        'brown',\n",
    "    ]     #   'gold',\n",
    "    for (i,j,c) in zip(filepaths,index,colors):\n",
    "        tweets = load_unlabeled_tweets(i)\n",
    "       # for k in tweets:\n",
    "\n",
    "        #    print(k)\n",
    "       #     X = token.texts_to_sequences([k])\n",
    "\n",
    "        \n",
    "      #  print(tweets)\n",
    "        X = token.texts_to_sequences(tweets)\n",
    "        X = pad_sequences(X)\n",
    "        \n",
    "        predictions = model.predict(X)\n",
    "        \n",
    "        pos = 0\n",
    "        for p in predictions:\n",
    "            if p[0] > p[1]:\n",
    "                pos += 1\n",
    "        df.set_value(index,'Percent Positive', float(pos) / predictions.size)\n",
    "        \n",
    "        \n",
    "        positiveonly = []\n",
    "        for i in predictions:\n",
    "            positiveonly.append(i[1])\n",
    "        \n",
    "        pos_df = pd.DataFrame(positiveonly)\n",
    "        pos_df.to_csv(\"stats/\"+j + \"_scores.csv\",header=None)\n",
    "        \n",
    "        loc, scale = expon.fit(positiveonly, loc=0)\n",
    "        \n",
    "        style.use('ggplot')  \n",
    "        plt.figure(figsize=(12, 9))  \n",
    "        plt.title('Sentiment Distribution of '+ j + ' Twitter Comments',fontsize=20)\n",
    "        plt.xlabel('Positive Sentiment Score',fontsize=16)\n",
    "        plt.ylabel('Percent of Scored Comments',fontsize=16)\n",
    "        plt.axis([0.0, 1.0, 0.0, 7.0])\n",
    "\n",
    "        plt.hist(positiveonly, density=True, bins=40 ,color=c)\n",
    "\n",
    "        plt.savefig('tweet_histograms/' + j + '.eps', format='eps', dpi=1200)\n",
    "        plt.savefig('tweet_histograms/' + j + '.png', format='png', dpi=1200)\n",
    "        tikz_save('tweet_histograms/' + j + '.tex',figureheight='4cm', figurewidth='6cm')\n",
    "        plt.show()\n",
    "    \n",
    "    print(df)\n",
    "    return df\n",
    "\n",
    "def cross_test():\n",
    "    \n",
    "    (sentence_list, emotion_list) = load_data()\n",
    "\n",
    "\n",
    "    ### Comment the Below line for all 18 emotions. This sorts into \"positive\" and \"negative\"\n",
    "    sentence_list, emotion_list = sort_to_2_emotions(sentence_list, emotion_list)\n",
    "\n",
    "    (tokenized_data,token) = tokenize(sentence_list,return_tokenizer=True)\n",
    "\n",
    "    (model, X_test) = train(tokenized_data, emotion_list)\n",
    "    \n",
    "    (sentence_list_self, emotion_list_self) = load_data()\n",
    "    \n",
    "    X = token.texts_to_sequences(sentence_list_self)\n",
    "    X = pad_sequences(X)\n",
    "    \n",
    "    (score,acc) = model.evaluate(x, emotion_list_self)\n",
    "    \n",
    "    print('acc')\n",
    "\n",
    "    \n",
    "\n",
    "#################################\n",
    "#############MAIN################\n",
    "#################################\n",
    "#   jupyter notebook is weird   #\n",
    "\n",
    "\n",
    "def test():\n",
    "    (sentence_list, emotion_list) = load_data()\n",
    "\n",
    "\n",
    "    ### Comment the Below line for all 18 emotions. This sorts into \"positive\" and \"negative\"\n",
    "    sentence_list, emotion_list = sort_to_2_emotions(sentence_list, emotion_list)\n",
    "\n",
    "    tokenized_data = tokenize(sentence_list)\n",
    "\n",
    "    (model, X_test) = train(tokenized_data, emotion_list)\n",
    "\n",
    "    #test(model, X_test, tokenized_data, sentence_list, emotion_list)\n",
    "\n",
    "    mistake_list = count_errors(model, tokenized_data, sentence_list, emotion_list,X_test)\n",
    "\n",
    "    graph_errors(mistake_list, emotion_list)\n",
    "\n",
    "df = make_comparison()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{llrrrr}\n",
      "\\toprule\n",
      "{} &   Emotion &  Total Predictions &  Correct &  False Positives &  False Negatives \\\\\n",
      "\\midrule\n",
      "0 &  negative &                671 &      514 &              157 &              102 \\\\\n",
      "1 &  positive &               1105 &     1003 &              102 &              157 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# fig = plt.figure(figsize=(20,4))\n",
    "#sns.barplot(x = ProjectData['emotion'].unique(), y=ProjectData['emotion'].value_counts())\n",
    "#plt.show()\n",
    "from matplotlib import cm\n",
    "#graph_errors(mistake_list, emotion_list)\n",
    "df.plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
