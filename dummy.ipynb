{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import base64\n",
    "import string\n",
    "import re\n",
    "from collections import Counter\n",
    "import sklearn\n",
    "import xlrd\n",
    "import nltk as nltk\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib.colors import ListedColormap\n",
    "from os import path\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n",
      "Loading Data...\n",
      "Data Loaded\n",
      "Tokenizing...\n",
      "Tokenization Completed\n",
      "Training...\n",
      "Epoch 1/13\n",
      "15539/15539 [==============================] - 61s 4ms/step - loss: 0.6506 - acc: 0.6145\n",
      "Epoch 2/13\n",
      "15539/15539 [==============================] - 47s 3ms/step - loss: 0.5696 - acc: 0.7033\n",
      "Epoch 3/13\n",
      "15539/15539 [==============================] - 46s 3ms/step - loss: 0.5214 - acc: 0.7416\n",
      "Epoch 4/13\n",
      "15539/15539 [==============================] - 46s 3ms/step - loss: 0.4873 - acc: 0.7656\n",
      "Epoch 5/13\n",
      "15539/15539 [==============================] - 50s 3ms/step - loss: 0.4660 - acc: 0.7869\n",
      "Epoch 6/13\n",
      "15539/15539 [==============================] - 61s 4ms/step - loss: 0.4420 - acc: 0.7958\n",
      "Epoch 7/13\n",
      "15539/15539 [==============================] - 59s 4ms/step - loss: 0.4210 - acc: 0.8117\n",
      "Epoch 8/13\n",
      "15539/15539 [==============================] - 58s 4ms/step - loss: 0.4129 - acc: 0.8176\n",
      "Epoch 9/13\n",
      "15539/15539 [==============================] - 47s 3ms/step - loss: 0.3959 - acc: 0.8264\n",
      "Epoch 10/13\n",
      "15539/15539 [==============================] - 53s 3ms/step - loss: 0.3860 - acc: 0.8282\n",
      "Epoch 11/13\n",
      "15539/15539 [==============================] - 47s 3ms/step - loss: 0.3792 - acc: 0.8309\n",
      "Epoch 12/13\n",
      "15539/15539 [==============================] - 52s 3ms/step - loss: 0.3723 - acc: 0.8393\n",
      "Epoch 13/13\n",
      "12928/15539 [=======================>......] - ETA: 8s - loss: 0.3661 - acc: 0.8387"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import base64\n",
    "import string\n",
    "import re\n",
    "from collections import Counter\n",
    "import sklearn\n",
    "import xlrd\n",
    "import nltk as nltk\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib.colors import ListedColormap\n",
    "from os import path\n",
    "from PIL import Image\n",
    "from __future__ import unicode_literals, print_function\n",
    "import plac\n",
    "import random\n",
    "from pathlib import Path\n",
    "import thinc.extra.datasets\n",
    "import pandas as pd\n",
    "import spacy\n",
    "from spacy.util import minibatch, compounding\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import matplotlib.style as style \n",
    "from numpy import array, unique, array_equal\n",
    "import keras\n",
    "max_fatures = 3500\n",
    "from keras import regularizers\n",
    "\n",
    "\n",
    "def load_data_self():\n",
    "    print(\"Loading Data...\")\n",
    "    PrimaryEmotion = pd.read_csv('emotion.xls.csv')\n",
    "    print(\"Data Loaded\")\n",
    "    return (PrimaryEmotion['sentence'], array(PrimaryEmotion['emotion']))\n",
    "\n",
    "\n",
    "\n",
    "def sort_to_2_emotions_self(sentence_list, emotion_list):\n",
    "    sorted_list = []\n",
    "    sorted_emo = []\n",
    "    for (data, emo) in zip(sentence_list, emotion_list):\n",
    "        if (emo == 'Joy' or emo == 'Love' or emo == 'Optimism' or emo == 'Awe' or emo == 'Trust'):\n",
    "            sorted_list.append(data)\n",
    "            sorted_emo.append(\"positive\")\n",
    "        if (emo == 'Anger' or emo == 'Disgust' or emo == 'Sadness' or emo == 'Aggression' or emo == 'Contempt' or emo == 'Disapproval' or emo == 'Remorse'):\n",
    "            sorted_list.append(data)\n",
    "            sorted_emo.append(\"negative\")\n",
    "    return (sorted_list, sorted_emo)\n",
    "\n",
    "def load_data():\n",
    "    print(\"Loading Data...\")\n",
    "    TwitterEmotion = pd.read_csv('text_emotion.csv')\n",
    "    print(\"Data Loaded\")\n",
    "    return (TwitterEmotion['content'], TwitterEmotion['sentiment'])\n",
    "\n",
    "def load_unlabeled_tweets(filepath):\n",
    "    print(\"Loading \",filepath)\n",
    "    return array(pd.read_csv(filepath,dtype=str,skip_blank_lines=True)['text'])\n",
    "\n",
    "#Below the data is sorted into nine emotion groups. Eight of the groups are the outter layer of the wheel, or the combinations of \n",
    "#two emotion groups. The ninth group is \"Ambiguous\" and \"Neutral\" put together.\n",
    "def sort_to_2_emotions(sentence_list, emotion_list):\n",
    "    sorted_list = []\n",
    "    sorted_emo = []\n",
    "    for (data, emo) in zip(sentence_list, emotion_list):\n",
    "        if (emo == 'enthusiam' or emo == 'love' or emo == 'happiness'):\n",
    "            sorted_list.append(data)\n",
    "            sorted_emo.append(\"positive\")\n",
    "        if (emo == 'sadness' or emo == 'hate'):\n",
    "            sorted_list.append(data)\n",
    "            sorted_emo.append(\"negative\")\n",
    "    return (sorted_list, sorted_emo)\n",
    "\n",
    "\n",
    "\n",
    "def tokenize(sentences,return_tokenizer=False):\n",
    "    print(\"Tokenizing...\")\n",
    "    tokenizer = Tokenizer(num_words=max_fatures, split=' ',lower=True)\n",
    "    tokenizer.fit_on_texts(sentences)\n",
    "    X = tokenizer.texts_to_sequences(sentences)\n",
    "    X = pad_sequences(X)\n",
    "    print(\"Tokenization Completed\")\n",
    "    if (return_tokenizer==True):\n",
    "        return(X,tokenizer)\n",
    "    return X\n",
    "\n",
    "\n",
    "\n",
    "def train(tokened_sentences, emotion_list,return_acc=False):\n",
    "    print(\"Training...\")\n",
    "    embed_dim = 128\n",
    "    lstm_out = 196\n",
    "    test_percent=0\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(max_fatures, embed_dim))#input_length = tokened_sentences.shape[1]))\n",
    "    model.add(SpatialDropout1D(0.7))\n",
    "    model.add(keras.layers.Dropout(.6))\n",
    "\n",
    "    model.add(LSTM(lstm_out, dropout=0.65, recurrent_dropout=0.65))\n",
    "    \n",
    "    # len(set(emotion_list)) is a hacky way of geting the number of unique elements\n",
    "    # in a regualar python list (non-numpy)\n",
    "    model.add(Dense(unique(emotion_list).size,activation='softmax'))\n",
    "    model.compile(loss = 'binary_crossentropy', optimizer=keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, amsgrad=True ),metrics = ['accuracy'])\n",
    "    #print(model.summary())\n",
    "\n",
    "    Y = pd.get_dummies(emotion_list).values\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(tokened_sentences,Y, test_size = test_percent, random_state = 152321326)\n",
    "    #print(X_train.shape,Y_train.shape)\n",
    "    #print(X_test.shape,Y_test.shape)\n",
    "    \n",
    "    batch_size = 32\n",
    "    hist = model.fit(X_train, Y_train, epochs = 13, batch_size=batch_size, verbose = 1,validation_split=.0)\n",
    "    print(\"Training Completed\")\n",
    "    print(\"Testing Against Control... (% of the data) \", test_percent)\n",
    "   # score,acc = model.evaluate(X_test, Y_test, verbose = 2, batch_size = batch_size)\n",
    "    #print(\"Score   :\", score)\n",
    "    #print(\"Accuracy:\", acc)\n",
    "  #  fig = plt.figure(figsize=(7,7))\n",
    "  #  plt.plot(hist.history['acc'])\n",
    "    #if(val_split != 0.0):\n",
    "  #  plt.plot(hist.history['val_acc'])\n",
    "  #  plt.title('Model Accuracy')\n",
    "  #  plt.ylabel('Accuracy')\n",
    "   # plt.xlabel('Epochs')\n",
    "    #plt.legend(['Training Set', 'Validation Set'], loc='upper left')\n",
    "  #  plt.show()\n",
    "  #  plot.savefig('Twitter_data_loss_plot.eps', format='eps', dpi=1200)\n",
    "    \n",
    "   # plt.plot(hist.history['loss'])\n",
    "   # if(val_split != 0.0):\n",
    "   # plt.plot(hist.history['val_loss'])\n",
    "   # plt.title('Model Loss')\n",
    "   # plt.ylabel('loss')\n",
    "   # plt.xlabel('epoch')\n",
    "   # plt.legend(['Training Set', 'Validation Set'], loc='upper left')\n",
    "   # plt.show()\n",
    "   # plt.savefig('Twitter_data_loss_plot.eps', format='eps', dpi=1200)\n",
    "    if(return_acc == True):\n",
    "        return (model, X_test,acc)\n",
    "    return (model, X_test)\n",
    "\n",
    "### When Splitting data (train_test_split), we don't retain where in the \n",
    "### origional set the data is located, thus it takes\n",
    "### a little trickery to see the results while while only testing against untrained data\n",
    "### top_predictions variable changes how many predictions given\n",
    "def test(model, X_test, tokenized_data, sentence_list, emotion_list, top_predictions=1):\n",
    "    predictions = model.predict(tokenized_data, batch_size=32)\n",
    "    error = 0\n",
    "    for i in range(len(predictions)):\n",
    "     \n",
    "        #  \"If the current tokenized data array is in X_test (untrained tokenized arrays)\n",
    "        \n",
    "        if(any(array_equal(tokenized_data[i], x) for x in X_test)):\n",
    "            print(\"\\n\\n\")\n",
    "\n",
    "            \n",
    "            pos = list(predictions[i]).index(max(predictions[i]))\n",
    "            if (unique(emotion_list)[pos] != emotion_list[i]):\n",
    "                error += 1\n",
    "            temp = predictions[i]\n",
    "            \n",
    "            print(sentence_list[i])\n",
    "\n",
    "            for j in range(top_predictions):\n",
    "                pos = list(temp).index(max(temp))\n",
    "                print(\"\\n # %s Predicted emotion : \",j+1, unique(emotion_list)[pos])\n",
    "                temp[pos] = 0\n",
    "            print(\"Actual emotion   : \", emotion_list[i])\n",
    "\n",
    "    print(\"%  Accuracy when against untrained set: \", 1- (float(error) / len(X_test)))\n",
    "\n",
    "def count_errors(model, tokenized_data, sentence_list, emotion_list, X_test):\n",
    "    dims =  len(unique(emotion_list))\n",
    "    mistake_list = np.zeros((dims,dims), dtype=np.int)\n",
    "    predictions = model.predict(tokenized_data, batch_size=32)\n",
    "    print(\"Total predictions:\", len(predictions))\n",
    "    for i in range(len(predictions)):\n",
    "        if(any(array_equal(tokenized_data[i], x) for x in X_test)):\n",
    "            pos = list(predictions[i]).index(max(predictions[i]))\n",
    "            mistake_list[list(unique(emotion_list)).index(emotion_list[i])][pos] += 1\n",
    "   # for i in range(len(mistake_list)):\n",
    "   #     for j in range(len(mistake_list)):\n",
    "   #         mistake_list[i][j] = mistake_list[i][j] * 100 / list(emotion_list).count(unique(emotion_list)[i]) \n",
    "    print(mistake_list)\n",
    "    return mistake_list\n",
    "\n",
    "\n",
    "def graph_errors(mistake_list, emotion_list):\n",
    "    dim = len(mistake_list[0])\n",
    "    \n",
    "    false =  np.zeros((dim,4), dtype=np.int)\n",
    "    \n",
    "    #total number of testing data for each category\n",
    "    for i in range(dim):\n",
    "        for j in range(dim):\n",
    "            false[i][0] += mistake_list[i][j]\n",
    "\n",
    "    \n",
    "    #true positives\n",
    "    for i in range(dim):\n",
    "              false[i][1] = mistake_list[i][i]\n",
    "    #false positives\n",
    "    for i in range(dim):\n",
    "        sum = 0\n",
    "        for j in range(dim):\n",
    "            if (i != j):\n",
    "                sum += mistake_list[i][j]\n",
    "        false[i][2] = sum\n",
    "   #     \n",
    "  #          #false Negatives\n",
    "    for i in range(dim):\n",
    "        sum = 0\n",
    "        for j in range(dim):\n",
    "            if (i != j):\n",
    "                sum += mistake_list[j][i]\n",
    "        false[i][3] = sum\n",
    "    df = pd.DataFrame(false)\n",
    "    #, \"False Positives\", \"False Negatives\"\n",
    "    \n",
    "    df.columns = [\"Total Predictions\", \"Correct\",\"False Positives\",\"False Negatives\"]\n",
    "    df.insert(0, \"Emotion\", np.unique(emotion_list))\n",
    "    (_, counts) = np.unique(emotion_list,return_counts=True)\n",
    "   # for i in range(counts.size):\n",
    "   #     counts[i] = counts[i] / 60\n",
    "   # df.insert(1,\"Amount of Data / 10\",counts)\n",
    "    print(df.to_latex())\n",
    "    df.plot.bar(x='Emotion',figsize=(12,8),colormap=cm.get_cmap('summer'))\n",
    "    #plot = sns.barplot(x=\"Emotion\",y=Correct, data=df)\n",
    "\n",
    "def make_comparison():\n",
    "    print(\"hello\")\n",
    "    \n",
    "    (sentence_list, emotion_list) = load_data()\n",
    "\n",
    "\n",
    "    ### Comment the Below line for all 18 emotions. This sorts into \"positive\" and \"negative\"\n",
    "    sentence_list, emotion_list = sort_to_2_emotions(sentence_list, emotion_list)\n",
    "\n",
    "    (tokenized_data,token) = tokenize(sentence_list,return_tokenizer=True)\n",
    "\n",
    "    (model, X_test) = train(tokenized_data, emotion_list)\n",
    "\n",
    "    #,'McDonald\\'s\n",
    "    #index = ['Chick-fil-A',\"Panera\",'McDonald\\'s','Chipotle','Pal\\'s']\n",
    "    index = ['Chick-fil-A',\"Panera\",'Chipotle','Pal\\'s']\n",
    "    columns= ['Percent Positive']\n",
    "    \n",
    "    df = pd.DataFrame(index=index, columns=columns)\n",
    "    \n",
    "    filepaths = ['tweets_unlabeled/out2.csv',\n",
    "                 'tweets_unlabeled/panera.csv',\n",
    "            #     'tweets_unlabeled/mc1.csv',\n",
    "                 'tweets_unlabeled/chip.csv',\n",
    "                 'tweets_unlabeled/pals.csv']\n",
    "    colors = [\n",
    "        'r',\n",
    "        'olivedrab',\n",
    "        'firebrick',\n",
    "        'turquoise',\n",
    "    ]     #   'gold',\n",
    "    for (i,j,c) in zip(filepaths,index,colors):\n",
    "        tweets = load_unlabeled_tweets(i)\n",
    "       # for k in tweets:\n",
    "\n",
    "        #    print(k)\n",
    "       #     X = token.texts_to_sequences([k])\n",
    "\n",
    "        \n",
    "      #  print(tweets)\n",
    "        X = token.texts_to_sequences(tweets)\n",
    "        X = pad_sequences(X)\n",
    "        \n",
    "        predictions = model.predict(X)\n",
    "        \n",
    "        pos = 0\n",
    "        for p in predictions:\n",
    "            if p[0] > p[1]:\n",
    "                pos += 1\n",
    "        df.set_value(index,'Percent Positive', float(pos) / predictions.size)\n",
    "        \n",
    "        \n",
    "        positiveonly = []\n",
    "        for i in predictions:\n",
    "            positiveonly.append(i[0])\n",
    "        style.use('ggplot')  \n",
    "        \n",
    "        plt.figure(figsize=(12, 9))  \n",
    "        plt.title('Sentiment Distribution of '+ j + ' Twitter Comments',fontsize=20)\n",
    "        plt.xlabel('Sentiment Score',fontsize=16)\n",
    "        plt.ylabel('Percent Probability',fontsize=16)\n",
    "        plt.hist(positiveonly, density=True, bins=40 ,color=c)\n",
    "\n",
    "        plt.savefig('tweet_histograms/' + j + '.eps', format='eps', dpi=1200)\n",
    "        plt.savefig('tweet_histograms/' + j + '.png', format='png', dpi=1200)\n",
    "        plt.show()\n",
    "    \n",
    "    print(df)\n",
    "    return df\n",
    "\n",
    "def cross_test():\n",
    "    \n",
    "    (sentence_list, emotion_list) = load_data()\n",
    "\n",
    "\n",
    "    ### Comment the Below line for all 18 emotions. This sorts into \"positive\" and \"negative\"\n",
    "    sentence_list, emotion_list = sort_to_2_emotions(sentence_list, emotion_list)\n",
    "\n",
    "    (tokenized_data,token) = tokenize(sentence_list,return_tokenizer=True)\n",
    "\n",
    "    (model, X_test) = train(tokenized_data, emotion_list)\n",
    "    \n",
    "    (sentence_list_self, emotion_list_self) = load_data()\n",
    "    \n",
    "    X = token.texts_to_sequences(sentence_list_self)\n",
    "    X = pad_sequences(X)\n",
    "    \n",
    "    (score,acc) = model.evaluate(x, emotion_list_self)\n",
    "    \n",
    "    print('acc')\n",
    "\n",
    "    \n",
    "\n",
    "#################################\n",
    "#############MAIN################\n",
    "#################################\n",
    "#   jupyter notebook is weird   #\n",
    "\n",
    "\n",
    "def test():\n",
    "    (sentence_list, emotion_list) = load_data()\n",
    "\n",
    "\n",
    "    ### Comment the Below line for all 18 emotions. This sorts into \"positive\" and \"negative\"\n",
    "    sentence_list, emotion_list = sort_to_2_emotions(sentence_list, emotion_list)\n",
    "\n",
    "    tokenized_data = tokenize(sentence_list)\n",
    "\n",
    "    (model, X_test) = train(tokenized_data, emotion_list)\n",
    "\n",
    "    #test(model, X_test, tokenized_data, sentence_list, emotion_list)\n",
    "\n",
    "    mistake_list = count_errors(model, tokenized_data, sentence_list, emotion_list,X_test)\n",
    "\n",
    "    graph_errors(mistake_list, emotion_list)\n",
    "    \n",
    "df = make_comparison()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{llrrrr}\n",
      "\\toprule\n",
      "{} &   Emotion &  Total Predictions &  Correct &  False Positives &  False Negatives \\\\\n",
      "\\midrule\n",
      "0 &  negative &                671 &      514 &              157 &              102 \\\\\n",
      "1 &  positive &               1105 &     1003 &              102 &              157 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# fig = plt.figure(figsize=(20,4))\n",
    "#sns.barplot(x = ProjectData['emotion'].unique(), y=ProjectData['emotion'].value_counts())\n",
    "#plt.show()\n",
    "from matplotlib import cm\n",
    "#graph_errors(mistake_list, emotion_list)\n",
    "df.plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
